{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyPEw07Pguju"
      },
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mrAK7Jy_FPzR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from functions.generation.prompt import load_prompt\n",
        "from functions.generation.generator import PunsGenerator\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carrega vari√°veis do arquivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Acessa as vari√°veis\n",
        "openai_api_key = os.getenv(\"openai_api_key\")\n",
        "maritaca_api_key = os.getenv(\"maritaca_api_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EaG3m7tPZnko"
      },
      "outputs": [],
      "source": [
        "# Mostrar todas as linhas do DataFrame\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_puns = 2\n",
        "# Carrega os prompts de gera√ß√£o utilizados\n",
        "prompt_generation_zero_shot = load_prompt('generation/zero_shot', num_puns//2)\n",
        "prompt_generation_few_shot = load_prompt('generation/few_shot', num_puns//2)\n",
        "prompt_generation_chain_of_thought = load_prompt('generation/chain_of_thought', num_puns//2)\n",
        "\n",
        "# Carrega os prompts de reconhecimento utilizados\n",
        "prompt_recognition_few_shot = load_prompt('recognition/few_shot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMRJc8Tl2vt2"
      },
      "source": [
        "## Gera√ß√£o de Trocadilho & Reconhecimento e Explica√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé≠ Rodando 1 batches...\n",
            "\n",
            "üì¶ Batch 1/1\n",
            "--------------------------------------------------\n",
            "['O eletricista adorou a aula de espanhol. Afinal, ele √© fluente em \"fase\".', 'Qual √© a bebida favorita dos programadores? O caf√© Java.']\n",
            "üî§ Gerados 2 trocadilhos.\n",
            "‚úÖ Resultados salvos!\n",
            "\n",
            "üèÅ Finalizado!\n",
            "üíæ Exportando hist√≥rico final...\n",
            "‚úÖ Exportado como puns_final.csv\n"
          ]
        }
      ],
      "source": [
        "generator = PunsGenerator(\n",
        "    openai_api_key=openai_api_key,\n",
        "    maritaca_api_key= maritaca_api_key,\n",
        "    use_sabia_generate=False  # ou True se quiser gerar com Sabi√°\n",
        ")\n",
        "\n",
        "generator.run_batch_process(prompt_generation_few_shot, prompt_recognition_few_shot, num_batches=1)\n",
        "\n",
        "print(\"üíæ Exportando hist√≥rico final...\")\n",
        "generator.get_history().to_csv(os.path.abspath('files\\puns_sintetico\\puns_final.csv'), index=False)\n",
        "print(\"‚úÖ Exportado como puns_final.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sSTUX1KGLi_"
      },
      "source": [
        "# An√°lise da Base Gerada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XanB5JXWZFAb"
      },
      "outputs": [],
      "source": [
        "df_synthetics_puns = pd.read_csv(os.path.abspath('files\\puns_sintetico\\puns_final.csv'))\n",
        "df_synthetics_puns = df_synthetics_puns[df_synthetics_puns['puns'].notnull()]\n",
        "df_synthetics_puns.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjYq85i8aH1E"
      },
      "outputs": [],
      "source": [
        "name_grupo = 'TROCADILHO_gpt-4o_few.csv'\n",
        "df_synthetics_puns['GRUPO'] = name_grupo\n",
        "df_synthetics_puns = df_synthetics_puns.head(100)\n",
        "df_synthetics_puns.to_csv(name_grupo, index=False)\n",
        "df_synthetics_puns.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5qFMIvnqF_F"
      },
      "outputs": [],
      "source": [
        "df_synthetics_puns"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hywUvuIdgoS4",
        "2Dx_onhd-JYR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "trocadilhos_cursor-kw5Bb9EX",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
